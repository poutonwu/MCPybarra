import sys
import os
import json
import pandas as pd
import numpy as np
import scipy
import sklearn
import statsmodels.api as sm
from ydata_profiling import ProfileReport
from mcp.server.fastmcp import FastMCP
from contextlib import redirect_stdout, redirect_stderr
import io
import traceback

# Initialize FastMCP server
mcp = FastMCP("mcp_data_analyzer")

# Global dictionary to store datasets
DATASETS = {}

# Pre-imported libraries for the run_script tool
AVAILABLE_LIBRARIES = {
    "pd": pd,
    "np": np,
    "scipy": scipy,
    "sklearn": sklearn,
    "sm": sm,
    "DATASETS": DATASETS,
}

@mcp.tool()
def load_csv(dataset_name: str, file_path: str) -> str:
    """
    Loads a dataset from a specified local CSV file into memory and assigns it a unique name.

    The function reads a CSV file into a pandas DataFrame and stores it in a global
    dictionary under the given `dataset_name`. This allows the dataset to be accessed
    by other tools in the session. Basic security checks are performed on the file path
    to prevent directory traversal.

    Args:
        dataset_name (str): A unique identifier for the dataset. If a dataset with
                            this name already exists, it will be overwritten.
                            Example: "titanic"
        file_path (str): The absolute or relative path to the CSV file to be loaded.
                         Example: "data/titanic.csv"

    Returns:
        str: A JSON string confirming the successful loading of the data, including
             the number of rows and columns.
             Example: '{"status": "success", "dataset_name": "titanic", "rows": 891, "columns": 12}'

    Raises:
        ValueError: If `dataset_name` or `file_path` are empty, or if the
                    `file_path` is potentially unsafe (e.g., contains '..').
        FileNotFoundError: If the specified `file_path` does not exist.
        pd.errors.ParserError: If the CSV file is malformed and cannot be parsed.
        Exception: For other potential loading or processing errors.
    """
    try:
        if not isinstance(dataset_name, str) or not dataset_name.strip():
            raise ValueError("dataset_name cannot be empty.")
        if not isinstance(file_path, str) or not file_path.strip():
            raise ValueError("file_path cannot be empty.")

        # Security: Prevent path traversal attacks. A more robust validation might be
        # needed for a production environment, like ensuring the path is within a
        # designated sandboxed directory.
        if ".." in file_path:
            raise ValueError(f"Invalid file path specified: {file_path}. Path traversal ('..') is not allowed.")

        df = pd.read_csv(file_path, encoding='utf-8-sig')
        DATASETS[dataset_name] = df

        response = {
            "status": "success",
            "dataset_name": dataset_name,
            "rows": len(df),
            "columns": len(df.columns)
        }
        return json.dumps(response)
    except FileNotFoundError:
        raise FileNotFoundError(f"The file was not found at the specified path: {file_path}")
    except pd.errors.ParserError as e:
        raise pd.errors.ParserError(f"Failed to parse the CSV file '{file_path}': {e}")
    except Exception as e:
        raise Exception(f"An unexpected error occurred while loading the CSV: {e}")

@mcp.tool()
def run_script(script_content: str) -> str:
    """
    Executes a provided Python script string with access to loaded datasets.

    The script runs in a controlled environment where it can access all loaded
    datasets via a global dictionary named `DATASETS`. It can use pre-imported
    libraries (pandas as pd, numpy as np, scipy, sklearn, statsmodels as sm)
    to perform complex data manipulations and analysis. Both standard output
    (stdout) and standard error (stderr) from the script execution are captured
    and returned.

    Args:
        script_content (str): A string containing the Python code to execute.
                              Example: "df = DATASETS['titanic']; print(df.describe())"

    Returns:
        str: A JSON string containing the standard output (stdout) and standard
             error (stderr) generated by the script, along with a final status
             message ('success' or 'error').
             Example: '{"status": "success", "stdout": "...", "stderr": ""}'
    """
    if not isinstance(script_content, str):
        return json.dumps({"status": "error", "stdout": "", "stderr": "script_content must be a string."})

    stdout_capture = io.StringIO()
    stderr_capture = io.StringIO()

    status = "success"

    try:
        # Redirect stdout and stderr to capture script output
        with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
            # Execute the script in a controlled environment with available libraries
            exec(script_content, AVAILABLE_LIBRARIES)
    except Exception:
        status = "error"
        # Capture the full traceback in stderr for debugging
        stderr_capture.write(traceback.format_exc())

    stdout = stdout_capture.getvalue()
    stderr = stderr_capture.getvalue()

    response = {
        "status": status,
        "stdout": stdout,
        "stderr": stderr
    }

    return json.dumps(response)

@mcp.tool()
def explore_data(dataset_name: str) -> str:
    """
    Performs comprehensive exploratory data analysis (EDA) on a specified dataset.

    This function uses the ydata-profiling library to generate a detailed report
    for the given dataset. The report includes a wide range of information such as
    descriptive statistics, data types, missing values, correlations, and
    visualizations. The entire report is returned as a JSON object, which can be
    used by a client application to render interactive visualizations and tables.

    Args:
        dataset_name (str): The unique identifier of the dataset to analyze.
                            Example: "titanic"

    Returns:
        str: A JSON string containing the full ydata-profiling report.

    Raises:
        ValueError: If the specified `dataset_name` does not exist in memory.
        Exception: For any other unexpected errors during report generation.
    """
    try:
        if dataset_name not in DATASETS:
            raise ValueError(f"Dataset '{dataset_name}' not found. Please load it first using load_csv.")

        df = DATASETS[dataset_name]

        # Generate the profile report
        profile = ProfileReport(df, title=f"Exploratory Data Analysis: {dataset_name}", explorative=True)

        # Return the report as a JSON string
        return profile.to_json()
    except ValueError as e:
        # Re-raise ValueError to be handled by the MCP framework
        raise e
    except Exception as e:
        # Catch any other unexpected errors during report generation
        raise Exception(f"An error occurred during data exploration for '{dataset_name}': {e}")


if __name__ == "__main__":
    # Ensure UTF-8 encoding for stdout to prevent encoding errors with special characters
    if sys.stdout.encoding.lower() != 'utf-8':
        sys.stdout.reconfigure(encoding='utf-8')

    # Run the MCP server
    mcp.run()